{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CauqzJXFeKS",
        "outputId": "b1317bf2-2dc9-456a-8fd9-589ebd4cb02f"
      },
      "outputs": [],
      "source": [
        "!pip install kagglehub\n",
        "!pip install json\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDU7dMQdFrQT"
      },
      "outputs": [],
      "source": [
        "instruction_for_dataset = \"extract the rdf from this message in N-tripple format\"\n",
        "instruction_for_llm = \"extract the detailed rdf from this message in N-triple format. Use detailed predicates. Don't copy full text from body. For example, <person:george_richards> <schema:jobTitle> \\\"President\\\", <msg:25> <prop:earlyLandCost> \\\"4000 USD per month\\\"^^<unit:USDollarPerMonth>. Optimize response for saving tokens\"\n",
        "instruction_for_llm_rus = \"Сгенерируй сообщение, похожее на это, чтобы оно было на русском языке\"\n",
        "instruction_for_llm_rus_rdf = \"extract the detailed rdf from this message in N-triple format. Use detailed predicates. Don't copy full text from body. For example, <person:george_richards> <schema:jobTitle> \\\"President\\\", <msg:25> <prop:earlyLandCost> \\\"4000 долларов в месяц\\\"^^<unit:USDollarPerMonth>. Optimize response for saving tokens\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEaX4L-oFuvZ",
        "outputId": "b25ea477-b10e-4ef5-bb89-aaeb160104e2"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import json\n",
        "\n",
        "\n",
        "used_id_file = 'message_ids.txt'\n",
        "dataset_file = \"english_dataset.jsonl\"\n",
        "\n",
        "\n",
        "def check_id(message, used_id):\n",
        "    lines = message.split('\\n')\n",
        "    for line in lines:\n",
        "        if ':' in line:\n",
        "            header_name = line.split(':', 1)[0].strip()\n",
        "            if header_name == \"Message-ID\":\n",
        "                message_id = line.split(':', 1)[1].strip()\n",
        "                if message_id in used_id:\n",
        "                    return True\n",
        "                else:\n",
        "                    return False\n",
        "\n",
        "\n",
        "\n",
        "def filter_email_headers(message, used_id_file):\n",
        "    \"\"\"Фильтрует заголовки email и обрезает пересланную часть\"\"\"\n",
        "    lines = message.split('\\n')\n",
        "    allowed_headers = {'Date', 'From', 'To'}\n",
        "    filtered_lines = []\n",
        "    in_headers = True\n",
        "    is_original = False\n",
        "\n",
        "    for line in lines:\n",
        "        # Проверяем, не началась ли пересланная часть\n",
        "        if \"Forwarded by\" in line:\n",
        "            break\n",
        "\n",
        "        #поиск нужных заголовков и добавление непустых строк\n",
        "        if in_headers:\n",
        "            if ':' in line:\n",
        "                header_name = line.split(':', 1)[0].strip()\n",
        "                if header_name in allowed_headers:\n",
        "                    filtered_lines.append(line)\n",
        "                elif header_name == \"Message-ID\":\n",
        "                    with open(used_id_file, 'a') as file:\n",
        "                        file.write(str(line.split(':', 1)[1].strip()) + \"\\n\")\n",
        "            elif line.strip() == \"\":\n",
        "                 in_headers = False\n",
        "        elif line.strip() != \"\":\n",
        "                filtered_lines.append(line)\n",
        "                is_original = True\n",
        "\n",
        "\n",
        "    if is_original:\n",
        "        return \"\\n\".join(filtered_lines)\n",
        "    else:\n",
        "         return \"---Forwarded message---\"\n",
        "\n",
        "\n",
        "def add_data(instruction, input, output, dataset_file):\n",
        "    new_item = {\n",
        "        \"instruction\": instruction,\n",
        "        \"input\": input,\n",
        "        \"output\": output\n",
        "    }\n",
        "    with open(dataset_file, \"a\", encoding=\"utf-8\") as file:\n",
        "        file.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def format_string_for_writing(response):\n",
        "    lines = response.split('\\n')\n",
        "    filtered_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip != \"\":\n",
        "            filtered_lines.append(line)\n",
        "    return \"    \".join(filtered_lines)\n",
        "\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"emails.csv\"\n",
        "\n",
        "# Load the dataset with iterator to read one message at a time\n",
        "df_iter = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"wcukierski/enron-email-dataset\",\n",
        "    file_path,\n",
        "    pandas_kwargs={\n",
        "        \"usecols\": [\"message\"],\n",
        "        \"chunksize\": 1  # Читаем по одному сообщению за раз\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-9h0m2cJBGD"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"sk-or-vv-8dc7fde61c37a92124dcf1a9f236066014c49f7ba4231cafa064e40792dfed0e\",\n",
        "    base_url=\"https://api.vsegpt.ru/v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g_NvDajoFyPc",
        "outputId": "322456c8-1fd5-4e0c-ac09-9eed0fbee995"
      },
      "outputs": [],
      "source": [
        "# создание датасета на английском языке\n",
        "with open('message_ids.txt', 'r') as file:\n",
        "    # Читаем все строки файла и удаляем символы переноса строки\n",
        "    used_id = [line.strip() for line in file.readlines()]\n",
        "\n",
        "counter = 0\n",
        "for i, chunk in enumerate(df_iter, 1):\n",
        "    if i <= 2000:\n",
        "      continue\n",
        "    input = chunk[\"message\"].iloc[0]\n",
        "    #print(input)\n",
        "    if check_id(input, used_id):\n",
        "        continue\n",
        "    input = filter_email_headers(input, used_id_file)\n",
        "    if input != \"---Forwarded message---\":\n",
        "        input = f\"\\n--- Message {i} ---\" + \"\\n\" + input\n",
        "        prompt = instruction_for_llm + \":\" + \"\\n\" + input\n",
        "        messages = []\n",
        "        #messages.append({\"role\": \"system\", \"content\": system_text})\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        response_big = client.chat.completions.create(\n",
        "            #model=\"deepseek/deepseek-chat-0324-alt\",\n",
        "            model=\"openai/gpt-4.1-nano\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            n=1,\n",
        "            max_tokens=3000\n",
        "        )\n",
        "        #print(\"Response BIG:\",response_big)\n",
        "        response = response_big.choices[0].message.content\n",
        "        print(input)\n",
        "        print(response)\n",
        "        response = format_string_for_writing(response)\n",
        "        input = format_string_for_writing(input)\n",
        "        add_data(instruction_for_dataset, input, response, dataset_file)\n",
        "        print(\"==ok==\")\n",
        "\n",
        "    counter += 1\n",
        "    if counter == 500:\n",
        "        break\n",
        "\n",
        "    # Если нужно ограничить количество сообщений\n",
        "    if i >= 4000:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PodJlEWc8Esu",
        "outputId": "0dc62b6d-c343-4402-f33a-525da2d4e29a"
      },
      "outputs": [],
      "source": [
        "# перевод датасета на русский язык\n",
        "with open('message_ids_rus.txt', 'r') as file:\n",
        "    # Читаем все строки файла и удаляем символы переноса строки\n",
        "    used_id = [line.strip() for line in file.readlines()]\n",
        "\n",
        "counter = 0\n",
        "for i, chunk in enumerate(df_iter, 1):\n",
        "    if i <= 1000:\n",
        "        continue\n",
        "    # Извлекаем первое (и единственное) сообщение из чанка\n",
        "    input = chunk[\"message\"].iloc[0]\n",
        "    #print(input)\n",
        "    if check_id(input, used_id):\n",
        "        continue\n",
        "    input = filter_email_headers(input, used_id_file)\n",
        "    if input != \"---Forwarded message---\":\n",
        "        input = f\"\\n--- Message {i} ---\" + \"\\n\" + input\n",
        "        prompt = instruction_for_llm_rus + \":\" + \"\\n\" + input\n",
        "        messages = []\n",
        "        #messages.append({\"role\": \"system\", \"content\": system_text})\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        response_big = client.chat.completions.create(\n",
        "            #model=\"deepseek/deepseek-chat-0324-alt\",\n",
        "            model=\"openai/gpt-4.1-nano\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            n=1,\n",
        "            max_tokens=3000\n",
        "        )\n",
        "        #print(\"Response BIG:\",response_big)\n",
        "        response = response_big.choices[0].message.content\n",
        "        print(response)\n",
        "        response = format_string_for_writing(response)\n",
        "        input = format_string_for_writing(input)\n",
        "        add_data(instruction_for_dataset, input, response, dataset_file)\n",
        "        print(\"==ok==\")\n",
        "\n",
        "\n",
        "    counter += 1\n",
        "    if counter == 300:\n",
        "      break\n",
        "\n",
        "    # Если нужно ограничить количество сообщений\n",
        "    if i >= 2000:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MXv8WZ5t-Jxo",
        "outputId": "ef9e3cbc-1a87-40a6-f077-4bca5a4867ed"
      },
      "outputs": [],
      "source": [
        "# создание датасета на русском языке\n",
        "def extract_attribute_from_jsonl(file_path, attribute_name):\n",
        "    values = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            data = json.loads(line)\n",
        "            if attribute_name in data:\n",
        "                values.append(data[attribute_name])\n",
        "    return values\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"/content/new_russian_dataset.jsonl\"\n",
        "attribute_name = \"output\"\n",
        "extracted_values = extract_attribute_from_jsonl(file_path, attribute_name)\n",
        "\n",
        "for i in range(len(extracted_values)):\n",
        "    # Извлекаем первое (и единственное) сообщение из чанка\n",
        "    input = extracted_values[i]\n",
        "    #print(input)\n",
        "    prompt = instruction_for_llm_rus_rdf + \":\" + \"\\n\" + input\n",
        "    messages = []\n",
        "    #messages.append({\"role\": \"system\", \"content\": system_text})\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    response_big = client.chat.completions.create(\n",
        "        #model=\"deepseek/deepseek-chat-0324-alt\",\n",
        "        model=\"openai/gpt-4.1-nano\",\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        n=1,\n",
        "        max_tokens=3000\n",
        "    )\n",
        "    #print(\"Response BIG:\",response_big)\n",
        "    response = response_big.choices[0].message.content\n",
        "    print(prompt)\n",
        "    print(\"=================\")\n",
        "    print(response)\n",
        "    response = format_string_for_writing(response)\n",
        "    input = format_string_for_writing(input)\n",
        "    add_data(instruction_for_dataset, input, response, dataset_file)\n",
        "    print(\"==ok==\")\n",
        "\n",
        "\n",
        "\n",
        "    # Если нужно ограничить количество сообщений\n",
        "    #if i >= 670:\n",
        "       # break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
